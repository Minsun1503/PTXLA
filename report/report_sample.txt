Báo cáo Phân tích Chi tiết Dự án: Hệ thống Chấm điểm Trắc nghiệm và Nhận dạng Ký tự Quang học Tự động (OMR & OCR)

1.0 Giới thiệu Tổng quan Dự án

Trong bối cảnh chuyển đổi số giáo dục đang diễn ra mạnh mẽ, việc tự động hóa các quy trình thủ công như chấm thi và quản lý thông tin ngày càng trở nên cấp thiết. Dự án này ra đời nhằm giải quyết thách thức đó bằng cách xây dựng một hệ thống tích hợp thông minh, kết hợp cả Nhận dạng Dấu hiệu Quang học (OMR) và Nhận dạng Ký tự Quang học (OCR). Tầm quan trọng chiến lược của giải pháp này nằm ở khả năng tăng cường đáng kể hiệu suất, giảm thiểu sai sót do con người gây ra và tiết kiệm hàng giờ lao động cho các nhà giáo dục.

Mục tiêu cốt lõi của dự án là xây dựng một giải pháp toàn diện để tự động hóa hai nhiệm vụ chính: chấm điểm các phiếu trả lời trắc nghiệm (OMR) và trích xuất thông tin văn bản như tên, mã số sinh viên (OCR) từ các tệp PDF được quét. Hệ thống được thiết kế để tối ưu hóa độ chính xác và cung cấp kết quả một cách nhanh chóng, trực quan.

Các tính năng chính của hệ thống bao gồm:

* Xử lý đầu vào từ file PDF: Hệ thống có khả năng làm việc trực tiếp với định dạng PDF, một định dạng tài liệu quét phổ biến nhất hiện nay. Điều này mang lại sự tiện lợi tối đa cho người dùng, loại bỏ các bước chuyển đổi định dạng thủ công.
* Tự động phát hiện và căn chỉnh tài liệu: Một trong những tính năng thông minh nhất là khả năng tự động tìm kiếm khung viền của phiếu trả lời trong ảnh quét. Sau khi phát hiện, hệ thống áp dụng biến đổi phối cảnh để "làm phẳng" tài liệu, loại bỏ hiệu quả các biến dạng do góc quét hoặc giấy bị cong, đảm bảo độ chính xác cho các bước xử lý sau.
* Cơ chế thiết lập tọa độ Hybrid: Đây là một quyết định thiết kế chiến lược. Hệ thống kết hợp thông minh giữa việc thiết lập thủ công một lần cho OMR và tự động hoàn toàn cho OCR. Khối đáp án OMR có cấu trúc lưới cứng nhắc và có thể dự đoán, do đó việc nội suy tọa độ toàn bộ lưới chỉ từ hai điểm neo do người dùng chọn là phương pháp cực kỳ hiệu quả. Ngược lại, các trường thông tin OCR (tên, mã số) có thể thay đổi về vị trí và số lượng trên các mẫu phiếu khác nhau. Vì vậy, việc sử dụng thuật toán phát hiện đường viền tự động là một giải pháp linh hoạt và mạnh mẽ hơn, giúp hệ thống thích ứng mà không cần viết lại mã nguồn.
* Chấm điểm OMR chính xác: Dựa trên tọa độ đã thiết lập, hệ thống quét các ô trả lời, xác định lựa chọn của học sinh và so sánh với đáp án chuẩn để tính điểm cuối cùng.
* Trích xuất thông tin OCR: Hệ thống sử dụng thư viện EasyOCR để đọc và trích xuất nội dung văn bản từ các vùng được phát hiện tự động, cho phép số hóa các thông tin quan trọng của thí sinh.
* Trực quan hóa và lưu trữ kết quả: Hệ thống không chỉ trả về dữ liệu thô mà còn tạo ra các tệp đầu ra hữu ích, bao gồm ảnh phiếu trả lời đã được chấm điểm (đánh dấu đúng/sai), ảnh báo cáo điểm số và tệp JSON chứa dữ liệu OCR.

Để hiện thực hóa các tính năng trên, dự án đã tận dụng một bộ công cụ và thư viện mạnh mẽ trong hệ sinh thái Python.

Công nghệ/Thư viện	Vai trò trong Dự án
Python	Ngôn ngữ lập trình chính, đóng vai trò kết nối tất cả các thành phần của hệ thống.
OpenCV	Thư viện thị giác máy tính cốt lõi, được sử dụng cho hầu hết các tác vụ từ tiền xử lý, phát hiện cạnh, biến đổi phối cảnh.
NumPy	Nền tảng cho tính toán khoa học, cung cấp cấu trúc mảng hiệu suất cao để biểu diễn và thao tác trên ma trận điểm ảnh.
EasyOCR	Thư viện OCR mạnh mẽ được sử dụng để nhận dạng và trích xuất văn bản, hỗ trợ đa ngôn ngữ bao gồm cả tiếng Việt.
pdf2image	Tiện ích giúp chuyển đổi các trang của tệp PDF thành đối tượng hình ảnh mà OpenCV có thể xử lý.
Poppler	Thư viện render PDF, là một phụ thuộc hệ thống bắt buộc để pdf2image có thể hoạt động.

Để hiểu cách các công nghệ này được tổ chức và phối hợp, phần tiếp theo sẽ đi sâu vào cấu trúc thư mục và mã nguồn của dự án.

2.0 Phân tích Cấu trúc Dự án

Một cấu trúc dự án được tổ chức tốt là nền tảng cho việc đảm bảo tính dễ bảo trì, khả năng mở rộng và sự rõ ràng của mã nguồn. Dự án này tuân thủ các nguyên tắc thiết kế module hóa, tách biệt rõ ràng các chức năng vào các tệp và thư mục riêng biệt.

Cấu trúc cây thư mục của dự án được trình bày như sau:

* main.py: Tệp thực thi chính của chương trình. Nó đóng vai trò là bộ điều phối, kiểm soát toàn bộ luồng hoạt động từ việc kiểm tra cấu hình, gọi các module xử lý cho đến khi hiển thị kết quả cuối cùng.
* requirements.txt: Tệp văn bản liệt kê tất cả các thư viện Python cần thiết để dự án có thể hoạt động. Điều này giúp đơn giản hóa quá trình cài đặt môi trường.
* src/: Thư mục chứa toàn bộ mã nguồn cốt lõi của ứng dụng, được chia thành các module chức năng.
  * config.py: Tệp cấu hình tập trung. Chứa tất cả các đường dẫn tệp, tham số xử lý ảnh và các hằng số quan trọng, giúp việc tùy chỉnh trở nên dễ dàng mà không cần sửa đổi logic chính.
  * pre_processing.py: Chịu trách nhiệm cho giai đoạn tiền xử lý, bao gồm đọc tệp PDF, phát hiện đường viền tài liệu và thực hiện biến đổi phối cảnh để làm phẳng ảnh.
  * omr_logic.py: Chứa logic chuyên biệt cho việc chấm điểm trắc nghiệm, từ việc tạo lưới tọa độ các ô đáp án đến việc phân tích điểm ảnh để xác định câu trả lời.
  * ocr_logic.py: Quản lý việc trích xuất văn bản bằng cách sử dụng EasyOCR trên các vùng ảnh được chỉ định.
  * measure_tool.py: Một công cụ tương tác, chỉ được kích hoạt trong lần chạy đầu tiên để người dùng thiết lập các điểm neo cho khối OMR và tự động phát hiện vùng OCR.
  * utils.py: Chứa các hàm tiện ích chung được sử dụng bởi nhiều module khác, chẳng hạn như hàm sắp xếp điểm và hàm biến đổi hình học.
  * ui.py: Chịu trách nhiệm cho tất cả các tương tác với người dùng, bao gồm hiển thị hộp thoại, vẽ kết quả lên ảnh và hiển thị cửa sổ kết quả cuối cùng.
* data/: Thư mục lưu trữ tất cả dữ liệu đầu vào.
  * raw/: Nơi chứa tệp PDF phiếu trả lời cần xử lý.
  * answer/: Chứa tệp answer_key.csv với đáp án đúng cho phần trắc nghiệm.
  * template/: Lưu trữ tệp coordinates.json sau khi người dùng thiết lập tọa độ lần đầu.
* output/: Thư mục nơi tất cả các kết quả đầu ra (ảnh, tệp JSON) được lưu trữ.
* poppler-25.11.0/: Chứa thư viện Poppler cần thiết để xử lý tệp PDF trên hệ điều hành Windows.

Sau khi đã hiểu các thành phần riêng lẻ và vai trò của chúng, phần tiếp theo sẽ trình bày cách chúng phối hợp với nhau trong một luồng xử lý hoàn chỉnh.

3.0 Luồng Hoạt động của Hệ thống

Luồng xử lý dữ liệu từ đầu đến cuối là xương sống của ứng dụng. Phần này sẽ trình bày chi tiết từng bước mà hệ thống thực hiện, từ khi nhận tệp PDF đầu vào cho đến khi xuất ra kết quả cuối cùng, thông qua hai kịch bản hoạt động chính.

3.1 Kịch bản 1: Thiết lập Lần đầu (First-Time Setup)

Kịch bản này xảy ra khi hệ thống được chạy lần đầu tiên và không tìm thấy tệp cấu hình tọa độ (coordinates.json).

1. Khởi tạo: Tệp main.py kiểm tra sự tồn tại của đường dẫn config.COORDINATES_PATH. Khi không tìm thấy, nó gọi hàm ui.prompt_coordinate_setup() để hiển thị một hộp thoại, hỏi người dùng có muốn bắt đầu quá trình thiết lập hay không.
2. Tải và Xử lý Ảnh: Nếu người dùng đồng ý, hàm measure_tool.get_coordinates_and_rois() được gọi. Bên trong hàm này, pre_processing.get_warped_image_from_pdf() được thực thi để chuyển đổi PDF thành ảnh, phát hiện, căn chỉnh và trả về hai hình ảnh quan trọng: ảnh phiếu trả lời đã được làm phẳng (warped_standard) và ảnh chứa các vùng bên ngoài phiếu (outside_image).
3. Giai đoạn 1 - Thiết lập OMR (Thủ công): Một cửa sổ tương tác hiển thị ảnh warped_standard. Người dùng được hướng dẫn click chuột vào tâm của ô đáp án đầu tiên (góc trên-trái, ví dụ: Câu 1, Lựa chọn A) và sau đó là tâm của ô đáp án cuối cùng (góc dưới-phải) của khối trắc nghiệm.
4. Giai đoạn 2 - Phát hiện Vùng OCR (Tự động): Ngay sau khi hai điểm neo được chọn, cửa sổ tương tác sẽ đóng lại. Hệ thống tự động xử lý ảnh outside_image ở chế độ nền. Nó sử dụng các thuật toán xử lý ảnh như cv2.threshold và cv2.findContours để tự động xác định các đường viền bao quanh các khối văn bản (như tên, MSSV, mã đề).
5. Lưu trữ Tọa độ: Tọa độ của hai điểm neo OMR và các hình chữ nhật bao quanh các vùng OCR được phát hiện sẽ được cấu trúc và lưu vào tệp coordinates.json. Tệp này sẽ được tái sử dụng cho tất cả các lần chạy sau.

3.2 Kịch bản 2: Vận hành Thông thường (Subsequent Runs)

Khi tệp coordinates.json đã tồn tại, hệ thống sẽ hoạt động ở chế độ hoàn toàn tự động.

1. Tải Cấu hình: main.py đọc tệp coordinates.json để lấy ra tọa độ hai điểm neo cho OMR (bubble_anchors) và danh sách các vùng chữ nhật cho OCR (ocr_regions).
2. Xử lý PDF: Tương tự như kịch bản 1, hàm pre_processing.get_warped_image_from_pdf() được gọi để lấy ảnh phiếu trả lời đã được căn chỉnh (warped_img) và ảnh vùng bên ngoài (outside_img).
3. Thực thi Chấm điểm: Hàm điều phối chính run_grading_process() được gọi, truyền vào các tọa độ và hình ảnh đã được chuẩn bị.
4. Xử lý OMR: Bên trong run_grading_process(), các hàm logic OMR được thực thi tuần tự:
  * omr_logic.generate_column_coordinates sử dụng hai điểm neo để nội suy và tính toán tọa độ của tất cả các ô đáp án còn lại.
  * omr_logic.grade_with_coordinates phân tích điểm ảnh tại mỗi tọa độ để xác định câu trả lời của học sinh.
  * omr_logic.calculate_score so sánh kết quả với đáp án và tính điểm cuối cùng.
5. Xử lý OCR: Hàm ocr_logic.extract_text_from_regions được gọi, nhận vào ảnh outside_image và danh sách các vùng OCR đã tải từ tệp cấu hình để trích xuất văn bản.
6. Tổng hợp và Hiển thị: Cuối cùng, ui.save_output_files được sử dụng để lưu tất cả các tệp kết quả (ảnh, JSON) vào thư mục output/, và ui.show_final_results hiển thị các ảnh kết quả trên màn hình đồng thời in thông tin OCR ra console.

Để hiểu sâu hơn về các thuật toán và logic đằng sau mỗi bước, phần tiếp theo sẽ phân tích chi tiết mã nguồn của từng module chức năng.

4.0 Phân tích Chi tiết Mã nguồn theo Module

Đây là phần cốt lõi của báo cáo, đi sâu phân tích từng module mã nguồn để làm rõ các thuật toán, cấu trúc dữ liệu và các quyết định thiết kế quan trọng.

4.1 Module Tiền xử lý (src/pre_processing.py và src/utils.py)

* Mục đích: Module này đóng vai trò là bước chuẩn bị dữ liệu đầu vào. Nhiệm vụ của nó là biến đổi một ảnh quét có thể bị nghiêng, méo hoặc chụp từ một góc thành một ảnh phẳng, được chuẩn hóa về kích thước và sẵn sàng cho việc phân tích OMR và OCR.
* Phân tích các hàm chính:
  * get_warped_image_from_pdf(): Đây là hàm chính của module, thực hiện một chuỗi các bước xử lý:
    1. Chuyển đổi PDF: Sử dụng convert_from_path từ thư viện pdf2image để đọc trang đầu tiên của tệp PDF và chuyển nó thành một đối tượng ảnh mà OpenCV có thể xử lý.
    2. Xử lý ảnh cơ bản: Gọi hàm preprocess_image() để thực hiện một chuỗi xử lý nhân quả: đầu tiên, chuyển đổi sang ảnh xám để đơn giản hóa việc xử lý; sau đó áp dụng làm mờ Gaussian để giảm nhiễu, một bước quan trọng để thuật toán Canny hoạt động ổn định hơn; và cuối cùng là phát hiện cạnh bằng Canny để làm nổi bật các đường viền chính của tài liệu.
    3. Tìm đường viền tài liệu: Gọi hàm find_document_contour() để tìm đường viền lớn nhất có 4 đỉnh trong ảnh cạnh, được giả định là đường viền của trang giấy.
    4. Tách vùng bên ngoài: Sử dụng utils.get_outside_of_contour() để tạo một mặt nạ từ đường viền đã tìm thấy, sau đó tách biệt vùng ảnh nằm bên ngoài phiếu trả lời. Vùng này sẽ được dùng cho OCR.
    5. Biến đổi phối cảnh: Sử dụng utils.four_point_transform() để "cắt" và "kéo" 4 đỉnh của đường viền tài liệu thành một hình chữ nhật hoàn hảo, tạo ra một ảnh phẳng, không bị biến dạng.
  * four_point_transform() (từ utils.py): Đây là một thuật toán kinh điển trong xử lý ảnh. Nó yêu cầu sắp xếp 4 điểm đầu vào theo một thứ tự nhất quán (trên-trái, trên-phải, dưới-phải, dưới-trái) thông qua hàm order_points. Sau đó, nó tính toán ma trận biến đổi phối cảnh bằng cv2.getPerspectiveTransform và áp dụng ma trận này lên ảnh gốc để tạo ra ảnh kết quả đã được làm phẳng.

4.2 Module Công cụ Thiết lập (src/measure_tool.py)

* Mục đích: Module này hoạt động như một công cụ tương tác, chỉ chạy một lần, cho phép người dùng thiết lập hệ thống một cách linh hoạt. Nó tạo ra một "template" tọa độ có thể tái sử dụng, giúp hệ thống thích ứng với các mẫu phiếu trả lời khác nhau mà không cần phải viết lại mã nguồn.
* Phân tích luồng hoạt động:
  * Giai đoạn 1 - Lấy điểm neo OMR: Hàm anchor_point_callback được liên kết với sự kiện click chuột (cv2.EVENT_LBUTTONDOWN). Khi người dùng click, tọa độ con trỏ chuột được ghi lại. Hàm này chỉ cho phép ghi lại đúng hai tọa độ, tương ứng với hai điểm neo cần thiết cho khối OMR.
  * Giai đoạn 2 - Tự động phát hiện vùng OCR: Logic này thể hiện một quyết định kiến trúc quan trọng. Sau khi hai điểm neo OMR được chọn, hệ thống lấy ảnh outside_image (vùng bên ngoài phiếu trả lời) được trả về từ module tiền xử lý. Việc tách biệt này (separation of concerns) cực kỳ hiệu quả: nó ngăn logic phát hiện OCR bị nhầm lẫn bởi các đường kẻ và ô tròn bên trong phiếu trả lời, cho phép nó tập trung hoàn toàn vào các vùng thông tin liên quan. Hàm chuyển ảnh sang nhị phân (cv2.threshold), tìm các đường viền (cv2.findContours), và sau đó lọc các đường viền theo diện tích để tự động xác định các vùng văn bản.
  * Lưu trữ: Dữ liệu cuối cùng, bao gồm hai điểm neo OMR và danh sách các hình chữ nhật OCR, được cấu trúc thành một dictionary và lưu vào tệp coordinates.json.

4.3 Module Logic OMR (src/omr_logic.py)

* Mục đích: Đây là module trung tâm cho việc chấm điểm trắc nghiệm. Nó chứa các thuật toán để xác định câu trả lời của học sinh từ ảnh và so sánh chúng với đáp án để tính điểm.
* Phân tích các hàm chính:
  * generate_column_coordinates(): Hàm này thể hiện một thuật toán nội suy tuyến tính thông minh. Chỉ từ hai điểm neo (góc trên-trái và dưới-phải của khối đáp án), nó tính toán được tọa độ của mọi ô đáp án khác bằng cách chia đều khoảng cách theo chiều ngang và chiều dọc, dựa trên số lượng câu hỏi và lựa chọn đã được định nghĩa trong config.py.
  * grade_with_coordinates(): Đây là hàm thực hiện quy trình chấm điểm chi tiết:
    1. Chuyển ảnh phiếu trả lời sang thang độ xám và áp dụng ngưỡng nhị phân. Việc sử dụng cờ cv2.THRESH_BINARY_INV là một chi tiết kỹ thuật quan trọng: nó đảo ngược ảnh, làm cho các dấu mực tô màu trắng (giá trị 255) và nền giấy màu đen (giá trị 0).
    2. Lặp qua từng câu hỏi và từng ô đáp án (A, B, C, D) trong câu hỏi đó.
    3. Tại mỗi tọa độ ô đáp án, hệ thống tạo một mặt nạ hình tròn (cv2.circle) có bán kính SCAN_RADIUS.
    4. Sử dụng cv2.countNonZero để đếm số lượng pixel trắng (điểm ảnh của mực) nằm trong vùng mặt nạ tròn. Bước này chỉ hiệu quả do ảnh đã được đảo ngược ở bước 1.
    5. Logic quyết định: Trong một câu hỏi, ô nào có số pixel trắng cao nhất và vượt qua một ngưỡng tối thiểu (PIXEL_THRESHOLD từ config.py) sẽ được coi là câu trả lời được chọn.
  * load_answer_key() và calculate_score(): Các hàm này đảm nhiệm việc đọc đáp án từ tệp CSV, so sánh với danh sách câu trả lời của học sinh đã được xác định ở bước trên, và cuối cùng tính điểm trên thang 10.

4.4 Module Logic OCR (src/ocr_logic.py)

* Mục đích: Vai trò của module này là trích xuất văn bản từ các vùng ảnh đã được xác định trước bởi module measure_tool.py, sử dụng thư viện EasyOCR.
* Phân tích các hàm chính:
  * Khởi tạo easyocr.Reader: Trình đọc OCR (reader) được khởi tạo một lần duy nhất ở cấp độ module ngay khi chương trình được nạp. Điều này giúp tối ưu hóa hiệu suất vì quá trình khởi tạo model khá tốn thời gian. Nó được cấu hình để nhận dạng cả tiếng Việt ('vi') và tiếng Anh ('en').
  * extract_text_from_regions(): Hàm này lặp qua từng vùng OCR được cung cấp:
    1. Cắt vùng quan tâm (ROI) từ ảnh đầu vào dựa trên tọa độ.
    2. Gọi preprocess_for_ocr() để chuẩn bị ROI (hiện tại chỉ chuyển sang ảnh xám, nhưng có thể mở rộng).
    3. Sử dụng reader.readtext() để thực hiện nhận dạng. Tham số paragraph=True là một tùy chọn hữu ích giúp EasyOCR tự động nhóm các từ hoặc dòng chữ gần nhau thành một khối văn bản mạch lạc, thay vì trả về từng từ riêng lẻ.
    4. Văn bản được trích xuất sau đó được làm sạch (loại bỏ khoảng trắng thừa) và trả về.

4.5 Module Giao diện Người dùng và Đầu ra (src/ui.py)

* Mục đích: Module này chịu trách nhiệm cho tất cả các tương tác với người dùng (thông qua các hộp thoại đơn giản) và việc tạo ra các tệp kết quả cuối cùng một cách trực quan và dễ hiểu.
* Phân tích các hàm chính:
  * draw_results_on_image(): Hàm này vẽ các kết quả trực quan lên ảnh phiếu trả lời. Nó sử dụng logic màu sắc rõ ràng: màu xanh lá cây cho câu trả lời đúng và màu đỏ cho câu trả lời sai. Đối với mỗi câu, nó khoanh tròn câu trả lời của học sinh. Nếu học sinh làm sai, nó sẽ đánh dấu thêm một chấm xanh nhỏ tại vị trí câu trả lời đúng.
  * create_score_display(): Thay vì ghi điểm trực tiếp lên ảnh gốc, hàm này tạo ra một ảnh hoàn toàn mới với nền trắng để hiển thị điểm số, số câu đúng và tổng số câu một cách rõ ràng, chuyên nghiệp.
  * save_output_files(): Hàm này tập trung việc lưu tất cả các sản phẩm đầu ra vào thư mục output/, bao gồm: scoring_result.png, score.png, outside_area.png (ảnh trực quan hóa vùng OCR), và ocr_results.json.
  * show_final_results(): Sau khi xử lý xong, hàm này hiển thị các ảnh kết quả trong các cửa sổ riêng biệt và in thông tin OCR đã trích xuất ra màn hình console.

4.6 Module Cấu hình (src/config.py)

* Mục đích: Tầm quan trọng của module này nằm ở việc tập trung tất cả các tham số, đường dẫn và các giá trị "ma thuật" vào một file duy nhất. Điều này giúp việc tùy chỉnh và bảo trì hệ thống trở nên cực kỳ dễ dàng, người dùng có thể thay đổi hoạt động của chương trình mà không cần chạm vào logic mã nguồn.
* Phân tích các tham số quan trọng:
  * Paths: PDF_PATH, OUTPUT_PATH, ANSWER_KEY_PATH, COORDINATES_PATH định nghĩa tất cả các đường dẫn vào/ra.
  * Image Processing: STANDARD_SIZE. Việc chuẩn hóa kích thước ảnh sau khi làm phẳng là mấu chốt của toàn bộ hệ thống. Nó đảm bảo rằng template tọa độ, được tạo ra chỉ một lần, vẫn giữ nguyên giá trị cho mọi lần quét tiếp theo, bất kể độ phân giải gốc của ảnh quét hay khoảng cách từ máy ảnh. Nếu không có bước này, hệ thống tọa độ sẽ không đáng tin cậy.
  * OMR Logic: NUM_QUESTIONS_PER_COLUMN, SCAN_RADIUS, PIXEL_THRESHOLD. Hai tham số cuối cùng có tác động trực tiếp đến độ chính xác. Tăng SCAN_RADIUS có thể giúp bắt được các dấu tô lớn hơn nhưng cũng có nguy cơ chồng lấn. PIXEL_THRESHOLD quyết định độ đậm tối thiểu của một dấu tô để được công nhận; nếu quá thấp, nó có thể nhận nhầm nhiễu, nếu quá cao, nó có thể bỏ qua các dấu tô quá nhạt.

Sau khi đã phân tích sâu về mã nguồn và cách các module tương tác, phần tiếp theo sẽ hướng dẫn cách cài đặt và sử dụng hệ thống một cách thực tế.

5.0 Hướng dẫn Cài đặt và Vận hành

Phần này cung cấp một hướng dẫn thực hành toàn diện để người dùng có thể thiết lập môi trường cần thiết và chạy ứng dụng một cách thành công.

5.1 Yêu cầu Môi trường

* Python: Phiên bản 3.8 trở lên.
* Poppler: Đây là một yêu cầu hệ thống bắt buộc cho thư viện pdf2image.
  * Đối với người dùng Windows, dự án đã cung cấp sẵn thư mục poppler-25.11.0. Tuy nhiên, bước quan trọng nhất là phải thêm đường dẫn đầy đủ đến thư mục poppler-25.11.0\Library\bin vào biến môi trường Path của hệ thống. Nếu không thực hiện bước này, chương trình sẽ không thể tìm thấy Poppler và sẽ báo lỗi PopplerNotInstalledError ngay khi cố gắng xử lý tệp PDF.

5.2 Cài đặt Thư viện

Mở một cửa sổ dòng lệnh (Terminal hoặc Command Prompt) trong thư mục gốc của dự án và chạy lệnh sau để cài đặt tất cả các thư viện Python cần thiết được liệt kê trong requirements.txt.

pip install -r requirements.txt


Lưu ý: Trong lần chạy đầu tiên, thư viện easyocr có thể sẽ tự động tải về các model nhận dạng ngôn ngữ. Quá trình này chỉ diễn ra một lần và yêu cầu kết nối Internet.

5.3 Cấu hình và Chuẩn bị Dữ liệu

1. Đặt tệp PDF chứa phiếu trả lời cần chấm vào thư mục data/raw/.
2. Đặt tệp đáp án (định dạng CSV) vào thư mục data/answer/answer_key.csv.
3. Mở tệp src/config.py để kiểm tra và đảm bảo các đường dẫn như PDF_PATH và ANSWER_KEY_PATH là chính xác.

5.4 Quy trình Vận hành

Để khởi chạy chương trình, sử dụng lệnh sau trong terminal:

python main.py


* Thiết lập Lần đầu:
  * Nếu không tìm thấy tệp coordinates.json, một hộp thoại sẽ xuất hiện để xin phép bắt đầu thiết lập.
  * Một cửa sổ tương tác sẽ mở ra. Người dùng cần thực hiện theo hướng dẫn trên console: click vào tâm của ô đáp án đầu tiên (góc trên-trái) và sau đó là tâm của ô đáp án cuối cùng (góc dưới-phải) của khối trắc nghiệm.
  * Sau khi hai điểm được chọn, cửa sổ sẽ tự động đóng lại và hệ thống sẽ tự động phát hiện các vùng OCR. Tọa độ sẽ được lưu lại cho các lần chạy sau.
* Các lần chạy sau:
  * Chương trình sẽ tự động đọc tệp coordinates.json đã lưu và thực hiện toàn bộ quy trình chấm điểm và nhận dạng mà không cần bất kỳ tương tác nào từ người dùng.

Sau khi đã nắm vững cách vận hành, phần cuối cùng sẽ phân tích các kết quả đầu ra, đánh giá hiệu quả của hệ thống và đề xuất các hướng cải tiến trong tương lai.

6.0 Phân tích Kết quả, Hạn chế và Hướng phát triển

Phần cuối cùng này nhằm mục đích đánh giá các kết quả mà hệ thống tạo ra, nhận diện một cách khách quan các điểm mạnh, điểm yếu và đề xuất các hướng cải tiến khả thi để nâng cao hiệu quả và tính năng của ứng dụng.

6.1 Diễn giải Kết quả Đầu ra

Hệ thống lưu trữ tất cả các kết quả xử lý vào thư mục output/, bao gồm:

* scoring_result.png: Đây là tệp ảnh trực quan nhất, hiển thị phiếu trả lời đã được chấm điểm. Các dấu hiệu màu sắc có ý nghĩa như sau:
  * Vòng tròn xanh: Khoanh quanh câu trả lời đúng của học sinh.
  * Vòng tròn đỏ: Khoanh quanh câu trả lời sai của học sinh.
  * Chấm xanh nhỏ: Nếu học sinh trả lời sai, một chấm xanh nhỏ sẽ được đặt tại vị trí đáp án đúng để đối chiếu.
* score.png: Một ảnh riêng biệt, hiển thị điểm số cuối cùng trên thang 10 và tổng số câu trả lời đúng một cách rõ ràng.
* outside_area.png: Hình ảnh này trực quan hóa vùng được sử dụng cho quá trình OCR. Nó là ảnh gốc với phần phiếu trắc nghiệm đã bị tô đen, chỉ để lại các vùng chứa thông tin văn bản như tên, MSSV.
* ocr_results.json: Một tệp JSON chứa kết quả trích xuất văn bản. Cấu trúc của tệp này là một dictionary, trong đó mỗi khóa (ví dụ: auto_roi_1, auto_roi_2) tương ứng với một vùng văn bản được phát hiện tự động và được sắp xếp từ trên xuống dưới, và giá trị là chuỗi văn bản được trích xuất từ vùng đó.

6.2 Đánh giá và Hạn chế

Dựa trên phân tích các thuật toán đã sử dụng, hệ thống có một số hạn chế tiềm ẩn cần được ghi nhận:

* Độ nhạy với chất lượng ảnh quét: Hiệu quả của hệ thống, đặc biệt là bước phát hiện cạnh và nhận dạng ký tự, phụ thuộc nhiều vào chất lượng ảnh đầu vào. Ảnh bị mờ, độ tương phản thấp, hoặc có bóng đổ có thể làm giảm độ chính xác của việc phát hiện đường viền tài liệu và OCR.
* Sự phụ thuộc vào mẫu phiếu cố định: Cơ chế "template" tọa độ hiện tại yêu cầu tất cả các phiếu trả lời được xử lý phải có cùng một bố cục. Bất kỳ sự thay đổi nào về vị trí của khối đáp án sẽ yêu cầu phải chạy lại quá trình thiết lập thủ công.
* Giới hạn của OCR: Thư viện EasyOCR hoạt động tốt với văn bản in, nhưng có thể gặp khó khăn với chữ viết tay hoặc các phông chữ quá cách điệu, dẫn đến kết quả trích xuất không chính xác.
* Ngưỡng OMR cố định: Tham số PIXEL_THRESHOLD được thiết lập cố định trong config.py. Giá trị này có thể không tối ưu cho tất cả các trường hợp, ví dụ như khi học sinh sử dụng các loại bút mực khác nhau hoặc tô đậm/nhạt không đều.

6.3 Hướng phát triển Tương lai

Để khắc phục các hạn chế và mở rộng tính năng, một số hướng phát triển tiềm năng có thể được xem xét:

* Giao diện người dùng đồ họa (GUI): Xây dựng một GUI hoàn chỉnh (sử dụng các thư viện như Tkinter hoặc PyQt) để thay thế cho công cụ console và các cửa sổ OpenCV đơn giản. Một GUI sẽ giúp quá trình thiết lập, cấu hình và xem kết quả trở nên thân thiện và chuyên nghiệp hơn.
* Xử lý hàng loạt (Batch Processing): Phát triển khả năng cho phép người dùng chọn một thư mục chứa nhiều tệp PDF để hệ thống tự động xử lý tất cả trong một lần chạy, giúp tăng năng suất đáng kể.
* Cơ chế phát hiện OMR/OCR linh hoạt hơn: Để khắc phục Sự phụ thuộc vào mẫu phiếu cố định đã nêu ở mục 6.2, một hướng phát triển quan trọng là nghiên cứu áp dụng các thuật toán học máy hoặc các kỹ thuật phát hiện đối tượng (ví dụ: YOLO) để tự động hóa hoàn toàn việc tìm kiếm khối đáp án và các vùng văn bản quan trọng, loại bỏ bước thiết lập thủ công ban đầu.
* Cải thiện độ chính xác OCR: Để giải quyết Giới hạn của OCR, có thể tích hợp các kỹ thuật hậu xử lý văn bản sau khi trích xuất. Ví dụ, sử dụng biểu thức chính quy (regex) để xác thực và định dạng lại dữ liệu có cấu trúc (như MSSV, Mã đề) hoặc đối chiếu tên với danh sách lớp để sửa lỗi chính tả.

Tóm lại, dự án đã thành công trong việc xây dựng một hệ thống tự động hóa chấm thi OMR và OCR hiệu quả, giải quyết một vấn đề thực tiễn trong ngành giáo dục. Mặc dù còn một số hạn chế, hệ thống này đã đặt một nền móng vững chắc và cho thấy tiềm năng phát triển to lớn để trở thành một công cụ hỗ trợ toàn diện và mạnh mẽ hơn trong tương lai.
